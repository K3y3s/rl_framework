{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = .99\n",
    "DECAY_FACTOR = .99995\n",
    "BATCH_SIZE = 64\n",
    "MAX_EPISODES = 800\n",
    "# MAX_EPISODES = 2\n",
    "ACCEPTABLE_AVERAGE_SCORE_THRESHOLD = 190\n",
    "MAX_ACCEPTABLE_AVG_SCORE_COUNTER = 100\n",
    "\n",
    "def Trainer(m, callbacks=[]):\n",
    "    memory = []\n",
    "    last_100_scores = deque(maxlen=100)\n",
    "    epsilon = 1.0\n",
    "    acceptable_avg_score_counter = 0\n",
    "\n",
    "    def choosePlay(state):\n",
    "        nonlocal epsilon\n",
    "        random_action = lambda: np.random.randint(N_ACTIONS)\n",
    "    \n",
    "        def predicted_action():\n",
    "            q_values = m(tf.expand_dims(state, 0))\n",
    "            action = tf.squeeze(tf.argmax(q_values, axis=-1))\n",
    "            return action.numpy()\n",
    "        \n",
    "        action =  random_action() if np.random.random() <= epsilon else predicted_action()\n",
    "        epsilon *= DECAY_FACTOR\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def obs_to_state(obs):\n",
    "        state = np.squeeze(obs)\n",
    "        return state\n",
    "\n",
    "    def play(state):\n",
    "        action = choosePlay(state)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        new_state = obs_to_state(obs)\n",
    "\n",
    "        return action, reward, new_state, done\n",
    "    \n",
    "    def train_step(state):\n",
    "        # Play to gain experience\n",
    "        action, reward, new_state, done = play(state)\n",
    "        new_state = np.zeros_like(state) if done else new_state\n",
    "\n",
    "        # Store experience in the memory bank\n",
    "        memory.append((state, action, reward, new_state))\n",
    "\n",
    "        # Train the network with a batch of the gained experience\n",
    "        batch = np.asarray(random.sample(memory, min(len(memory), BATCH_SIZE)), dtype=object)\n",
    "        q_s_a = m.predict(np.stack(batch[:, 0], axis = 0))  #Q(s,a)   \n",
    "        q_s_a_next = m.predict(np.stack(batch[:, 3], axis = 0))  #Q(s',a)\n",
    "\n",
    "        for item_id in range(batch.shape[0]):\n",
    "            if np.array_equal(batch[item_id, 3], np.zeros(N_STATES)):\n",
    "                q_s_a[item_id, batch[item_id, 1]] = batch[item_id, 2]\n",
    "            else:\n",
    "                q_s_a[item_id, batch[item_id, 1]] = batch[item_id, 2] + GAMMA*np.amax(q_s_a_next[item_id, :])\n",
    "\n",
    "        m.fit(np.stack(batch[:, 0], axis = 0), q_s_a, batch_size=BATCH_SIZE, verbose=0, callbacks=callbacks)\n",
    "        \n",
    "        return new_state, reward, done\n",
    "    \n",
    "    def record_episode(episode_id, step_id, score, reward, results):\n",
    "        nonlocal acceptable_avg_score_counter\n",
    "\n",
    "        # Update the last 100 scores queue with the latest score\n",
    "        last_100_scores.append(score)\n",
    "\n",
    "        # Collect episode results\n",
    "        mean_last_100_scores = mean(last_100_scores)\n",
    "        results.append((step_id, reward, score, mean_last_100_scores))\n",
    "        \n",
    "        # Increment the counter if the episode scores past the acceptance threshold\n",
    "        # Reset the counter if the episode falls below the acceptance threshold\n",
    "        if mean_last_100_scores > ACCEPTABLE_AVERAGE_SCORE_THRESHOLD:\n",
    "            acceptable_avg_score_counter += 1\n",
    "        else:\n",
    "            acceptable_avg_score_counter = 0\n",
    "\n",
    "        print(\n",
    "            'Episode:', episode_id,\n",
    "            'Steps:', step_id,\n",
    "            'Score:', score,\n",
    "            '100_rolling_average:', mean_last_100_scores,\n",
    "            'Acceptable Average Score Count:', acceptable_avg_score_counter,\n",
    "        )\n",
    "\n",
    "    def train(episodes=MAX_EPISODES, steps=1000):\n",
    "        results = []\n",
    "\n",
    "        for episode_id in range(episodes):\n",
    "            obs = env.reset()\n",
    "            state = obs_to_state(obs)\n",
    "            score = 0\n",
    "\n",
    "            for step_id in range(steps):\n",
    "                state, reward, done = train_step(state)\n",
    "                score += reward\n",
    "                \n",
    "                if done:\n",
    "                    record_episode(episode_id, step_id, score, reward, results)\n",
    "                    break\n",
    "            \n",
    "            # Terminate training if the average score meet the acceptance threshold\n",
    "            # for MAX_ACCEPTABLE_AVG_SCORE_COUNTER episodes in sequence.\n",
    "            if acceptable_avg_score_counter >= MAX_ACCEPTABLE_AVG_SCORE_COUNTER:\n",
    "                break\n",
    "\n",
    "        return results\n",
    "    \n",
    "    return train\n",
    "\n",
    "trainer = Trainer(model)\n",
    "results = trainer()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
